{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwriting to Text Recognition Project\n",
    "Pranav Thiriveedhi\n",
    "\n",
    "Dataset (Train, Test, Validation) from Kaggle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Keras to build model that detects handwriting\n",
    "Model: CRNN which is CNN + RNN\n",
    "\n",
    "Trained using: CTC (Connectionist Temporal Classification) Loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries (python packages)\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries (ML packages)\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Bidirectional, LSTM, Dense, Lambda, Activation, BatchNormalization, Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Train, Test and Validation data\n",
    "\n",
    "train = pd.read_csv('/Users/pranavthiriveedhi1/Desktop/projects/Handwriting_Recognition/written_name_train_v2.csv')\n",
    "test = pd.read_csv('/Users/pranavthiriveedhi1/Desktop/projects/Handwriting_Recognition/written_name_test_v2.csv')\n",
    "validation = pd.read_csv('/Users/pranavthiriveedhi1/Desktop/projects/Handwriting_Recognition/written_name_validation_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaNs in train set      :  0\n",
      "Number of NaNs in validation set :  0\n"
     ]
    }
   ],
   "source": [
    "# Cleaning data by removing NA values\n",
    "\n",
    "print(\"Number of NaNs in train set      : \", train['IDENTITY'].isnull().sum())\n",
    "print(\"Number of NaNs in validation set : \", validation['IDENTITY'].isnull().sum())\n",
    "\n",
    "train.dropna(axis=0, inplace=True)\n",
    "validation.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['IDENTITY'] != 'UNREADABLE']\n",
    "validation = validation[validation['IDENTITY'] != 'UNREADABLE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all labels to uppercase\n",
    "\n",
    "train['IDENTITY'] = train['IDENTITY'].str.upper()\n",
    "validation['IDENTITY'] = validation['IDENTITY'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(inplace = True, drop=True) \n",
    "validation.reset_index(inplace = True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess images\n",
    "\n",
    "def preprocess(img):\n",
    "    (h, w) = img.shape\n",
    "    final_img = np.ones([64, 256])*255 # blank white image\n",
    "    # crop\n",
    "    if w > 256:\n",
    "        img = img[:, :256]  \n",
    "    if h > 64:\n",
    "        img = img[:64, :]    \n",
    "    \n",
    "    final_img[:h, :w] = img\n",
    "    return cv2.rotate(final_img, cv2.ROTATE_90_CLOCKWISE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 50000\n",
    "valid_size = 5000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train 50,000 images and Validate 5,000 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = []\n",
    "\n",
    "for i in range(train_size):\n",
    "    img_dir = '/Users/pranavthiriveedhi1/Desktop/projects/Handwriting_Recognition/train/'+train.loc[i, 'FILENAME']\n",
    "    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
    "    image = preprocess(image)\n",
    "    image = image/255.\n",
    "    train_x.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x = []\n",
    "\n",
    "for i in range(valid_size):\n",
    "    img_dir = '/Users/pranavthiriveedhi1/Desktop/projects/Handwriting_Recognition/validation/'+validation.loc[i, 'FILENAME']\n",
    "    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
    "    image = preprocess(image)\n",
    "    image = image/255.\n",
    "    valid_x.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape arrays\n",
    "train_x = np.array(train_x).reshape(-1, 256, 64, 1)\n",
    "valid_x = np.array(valid_x).reshape(-1, 256, 64, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labeling for CTC Loss\n",
    "\n",
    "alphabets = u\"ABCDEFGHIJKLMNOPQRSTUVWXYZ-' \"\n",
    "max_str_len = 24 # max length of input labels\n",
    "num_of_characters = len(alphabets) + 1 # +1 for ctc pseudo blank\n",
    "num_of_timestamps = 64 # max length of predicted labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_num(label):\n",
    "    label_num = []\n",
    "    for ch in label:\n",
    "        label_num.append(alphabets.find(ch))\n",
    "        \n",
    "    return np.array(label_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_to_label(num):\n",
    "    ret = \"\"\n",
    "    for ch in num:\n",
    "        if ch == -1:  # CTC Blank\n",
    "            break\n",
    "        else:\n",
    "            ret+=alphabets[ch]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRANAV \n",
      " [15 17  0 13  0 21]\n"
     ]
    }
   ],
   "source": [
    "name = 'PRANAV'\n",
    "print(name, '\\n',label_to_num(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.ones([train_size, max_str_len]) * -1\n",
    "train_label_len = np.zeros([train_size, 1])\n",
    "train_input_len = np.ones([train_size, 1]) * (num_of_timestamps-2)\n",
    "train_output = np.zeros([train_size])  \n",
    "\n",
    "valid_y = np.ones([valid_size, max_str_len]) * -1\n",
    "valid_label_len = np.zeros([valid_size, 1])\n",
    "valid_input_len = np.ones([valid_size, 1]) * (num_of_timestamps-2)\n",
    "valid_output = np.zeros([valid_size])\n",
    "\n",
    "for i in range(valid_size):\n",
    "    valid_label_len[i] = len(validation.loc[i, 'IDENTITY'])\n",
    "    valid_y[i, 0:len(validation.loc[i, 'IDENTITY'])]= label_to_num(validation.loc[i, 'IDENTITY'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label :  NOUR \n",
      "train_y :  [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1.] \n",
      "train_label_len :  [0.] \n",
      "train_input_len :  [62.]\n"
     ]
    }
   ],
   "source": [
    "print('True label : ',train.loc[100, 'IDENTITY'] , '\\ntrain_y : ',train_y[100],'\\ntrain_label_len : ',train_label_len[100], \n",
    "      '\\ntrain_input_len : ', train_input_len[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = Input(shape=(256, 64, 1), name='input')\n",
    "\n",
    "inner = Conv2D(32, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(input_data)  \n",
    "inner = BatchNormalization()(inner)\n",
    "inner = Activation('relu')(inner)\n",
    "inner = MaxPooling2D(pool_size=(2, 2), name='max1')(inner)\n",
    "\n",
    "inner = Conv2D(64, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)\n",
    "inner = BatchNormalization()(inner)\n",
    "inner = Activation('relu')(inner)\n",
    "inner = MaxPooling2D(pool_size=(2, 2), name='max2')(inner)\n",
    "inner = Dropout(0.3)(inner)\n",
    "\n",
    "inner = Conv2D(128, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)\n",
    "inner = BatchNormalization()(inner)\n",
    "inner = Activation('relu')(inner)\n",
    "inner = MaxPooling2D(pool_size=(1, 2), name='max3')(inner)\n",
    "inner = Dropout(0.3)(inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 256, 64, 1)]      0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 256, 64, 32)       320       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256, 64, 32)      128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256, 64, 32)       0         \n",
      "                                                                 \n",
      " max1 (MaxPooling2D)         (None, 128, 32, 32)       0         \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 128, 32, 64)       18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128, 32, 64)      256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 128, 32, 64)       0         \n",
      "                                                                 \n",
      " max2 (MaxPooling2D)         (None, 64, 16, 64)        0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64, 16, 64)        0         \n",
      "                                                                 \n",
      " conv3 (Conv2D)              (None, 64, 16, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 64, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 64, 16, 128)       0         \n",
      "                                                                 \n",
      " max3 (MaxPooling2D)         (None, 64, 8, 128)        0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64, 8, 128)        0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 64, 1024)          0         \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 64, 64)            65600     \n",
      "                                                                 \n",
      " lstm1 (Bidirectional)       (None, 64, 512)           657408    \n",
      "                                                                 \n",
      " lstm2 (Bidirectional)       (None, 64, 512)           1574912   \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 64, 30)            15390     \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 64, 30)            0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,406,878\n",
      "Trainable params: 2,406,430\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# CNN to RNN\n",
    "inner = Reshape(target_shape=((64, 1024)), name='reshape')(inner)\n",
    "inner = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)\n",
    "\n",
    "## RNN\n",
    "inner = Bidirectional(LSTM(256, return_sequences=True), name = 'lstm1')(inner)\n",
    "inner = Bidirectional(LSTM(256, return_sequences=True), name = 'lstm2')(inner)\n",
    "\n",
    "## OUTPUT\n",
    "inner = Dense(num_of_characters, kernel_initializer='he_normal',name='dense2')(inner)\n",
    "y_pred = Activation('softmax', name='softmax')(inner)\n",
    "\n",
    "model = Model(inputs=input_data, outputs=y_pred)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the ctc loss function\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = Input(name='gtruth_labels', shape=[max_str_len], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "ctc_loss = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "model_final = Model(inputs=[input_data, labels, input_length, label_length], outputs=ctc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 39s 237ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(valid_x)\n",
    "decoded = K.get_value(K.ctc_decode(preds, input_length=np.ones(preds.shape[0])*preds.shape[1], \n",
    "                                   greedy=True)[0][0])\n",
    "\n",
    "prediction = []\n",
    "for i in range(valid_size):\n",
    "    prediction.append(num_to_label(decoded[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct characters predicted : 3.72%\n",
      "Correct words predicted      : 0.00%\n"
     ]
    }
   ],
   "source": [
    "y_true = validation.loc[0:valid_size, 'IDENTITY']\n",
    "correct_char = 0\n",
    "total_char = 0\n",
    "correct = 0\n",
    "\n",
    "for i in range(valid_size):\n",
    "    pr = prediction[i]\n",
    "    tr = y_true[i]\n",
    "    total_char += len(tr)\n",
    "    \n",
    "    for j in range(min(len(tr), len(pr))):\n",
    "        if tr[j] == pr[j]:\n",
    "            correct_char += 1\n",
    "            \n",
    "    if pr == tr :\n",
    "        correct += 1 \n",
    "    \n",
    "print('Correct characters predicted : %.2f%%' %(correct_char*100/total_char))\n",
    "print('Correct words predicted      : %.2f%%' %(correct*100/valid_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
